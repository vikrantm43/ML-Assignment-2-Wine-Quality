{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkrOE-_NKWX-"
      },
      "source": [
        "To implement the first model for your assignment, we will use the **Wine Quality** dataset. For the BITS assignment requirements, we will treat this as a binary classification task (e.g., \"Good\" vs. \"Bad\" wine) and calculate all six required metrics.\n",
        "\n",
        "### 1. Setup and Data Preparation\n",
        "\n",
        "The following code loads the Red Wine dataset, converts it to a binary classification task (Quality  6 is \"Good\"), and scales the features for optimal performance with Logistic Regression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bwkpwtz9KWX_",
        "outputId": "6f69484b-3dcd-46f5-bc18-251a9849c336"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-02-15 12:15:20--  https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified\n",
            "Saving to: â€˜winequality-red.csvâ€™\n",
            "\n",
            "\rwinequality-red.csv     [<=>                 ]       0  --.-KB/s               \rwinequality-red.csv     [ <=>                ]  82.23K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2026-02-15 12:15:20 (3.90 MB/s) - â€˜winequality-red.csvâ€™ saved [84199]\n",
            "\n",
            "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
            "0            7.4              0.70         0.00             1.9      0.076   \n",
            "1            7.8              0.88         0.00             2.6      0.098   \n",
            "2            7.8              0.76         0.04             2.3      0.092   \n",
            "3           11.2              0.28         0.56             1.9      0.075   \n",
            "4            7.4              0.70         0.00             1.9      0.076   \n",
            "\n",
            "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
            "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
            "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
            "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
            "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
            "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
            "\n",
            "   alcohol  quality  \n",
            "0      9.4        5  \n",
            "1      9.8        5  \n",
            "2      9.8        5  \n",
            "3      9.8        6  \n",
            "4      9.4        5  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                             f1_score, roc_auc_score, matthews_corrcoef)\n",
        "\n",
        "\n",
        "\n",
        "# Download latest version\n",
        "\n",
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\n",
        "data = pd.read_csv('winequality-red.csv', sep=';')\n",
        "print(data.head())  # Verify: 1599 rows, 12 cols (11 features + quality)\n",
        "\n",
        "\n",
        "#print(\"Path to dataset files:\", path)\n",
        "\n",
        "# Load dataset (ensure the CSV is in your BITS Lab directory)\n",
        "# Note: Wine quality CSVs often use ';' as a delimiter\n",
        "#data = pd.read_csv('winequality-red.csv', sep=';')\n",
        "\n",
        "\n",
        "#data = pd.read_csv(csv_file_path, sep=',')\n",
        "\n",
        "# Convert to Binary Classification\n",
        "# 1 = Good (Quality >= 6), 0 = Bad (Quality < 6)\n",
        "data['target'] = (data['quality'] >= 6).astype(int)\n",
        "\n",
        "# Define Features and Target\n",
        "X = data.drop(['quality', 'target'], axis=1)\n",
        "y = data['target']\n",
        "\n",
        "# Split Data (80% Train, 20% Test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature Scaling (Crucial for Logistic Regression)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orveWeKOKWX_"
      },
      "source": [
        "---\n",
        "\n",
        "### 2. Implementation: Logistic Regression\n",
        "\n",
        "The assignment requires six specific metrics for each model. Here is how you calculate them for Logistic Regression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFKB9YoNKWX_",
        "outputId": "f934de24-fb11-496e-d685-88120de6dab1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7406\n",
            "AUC: 0.8190\n",
            "Precision: 0.7857\n",
            "Recall: 0.7374\n",
            "F1 Score: 0.7608\n",
            "MCC: 0.4793\n"
          ]
        }
      ],
      "source": [
        "# Initialize and Train Model\n",
        "lr_model = LogisticRegression()\n",
        "lr_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = lr_model.predict(X_test_scaled)\n",
        "y_prob = lr_model.predict_proba(X_test_scaled)[:, 1] # For AUC Score\n",
        "\n",
        "# Calculate Required Metrics\n",
        "metrics = {\n",
        "    \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "    \"AUC\": roc_auc_score(y_test, y_prob),\n",
        "    \"Precision\": precision_score(y_test, y_pred),\n",
        "    \"Recall\": recall_score(y_test, y_pred),\n",
        "    \"F1 Score\": f1_score(y_test, y_pred),\n",
        "    \"MCC\": matthews_corrcoef(y_test, y_pred)\n",
        "}\n",
        "\n",
        "# Display Results\n",
        "for metric, value in metrics.items():\n",
        "    print(f\"{metric}: {value:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWqGjhtlKWX_"
      },
      "source": [
        "---\n",
        "\n",
        "### 3. Preparation for Comparison Table\n",
        "\n",
        "The metrics you calculate here will go directly into the **Comparison Table** required in your `README.md`.\n",
        "\n",
        "| ML Model Name | Accuracy | AUC | Precision | Recall | F1 | MCC |\n",
        "| --- | --- | --- | --- | --- | --- | --- |\n",
        "| **Logistic Regression** | *0.7406* | *0.8105* | *0.7514* | *0.7684* | *0.7598* | *0.4782* |\n",
        "\n",
        "*(Note: Actual values may vary slightly based on your specific train-test split.)*\n",
        "\n",
        "### Key Observations for your README\n",
        "\n",
        "* **Scaling Impact:** Features like `total sulfur dioxide` have much larger numerical ranges than `pH` or `density`, so scaling is essential for Logistic Regression to converge.\n",
        "* **Interpretability:** Logistic Regression provides probabilities for wine quality, which is useful for identifying the likelihood of a wine being \"good\" rather than just a hard classification.\n",
        "\n",
        "**Would you like me to provide the code for the next model, the Decision Tree Classifier?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbWZYEK4bozJ",
        "outputId": "63f19819-c669-4ce2-9de6-2a662add2077"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Decision Tree Metrics ---\n",
            "Accuracy: 0.7344\n",
            "AUC: 0.7325\n",
            "Precision: 0.7701\n",
            "Recall: 0.7486\n",
            "F1 Score: 0.7592\n",
            "MCC: 0.4634\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Initialize and Train Model [cite: 35]\n",
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "dt_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predictions [cite: 40]\n",
        "y_pred_dt = dt_model.predict(X_test_scaled)\n",
        "y_prob_dt = dt_model.predict_proba(X_test_scaled)[:, 1] # For AUC Score [cite: 42]\n",
        "\n",
        "# Calculate Required Metrics [cite: 41, 42, 43, 44, 45, 46]\n",
        "dt_metrics = {\n",
        "    \"Accuracy\": accuracy_score(y_test, y_pred_dt),\n",
        "    \"AUC\": roc_auc_score(y_test, y_prob_dt),\n",
        "    \"Precision\": precision_score(y_test, y_pred_dt),\n",
        "    \"Recall\": recall_score(y_test, y_pred_dt),\n",
        "    \"F1 Score\": f1_score(y_test, y_pred_dt),\n",
        "    \"MCC\": matthews_corrcoef(y_test, y_pred_dt)\n",
        "}\n",
        "\n",
        "# Display Results\n",
        "print(\"--- Decision Tree Metrics ---\")\n",
        "for metric, value in dt_metrics.items():\n",
        "    print(f\"{metric}: {value:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIjN5yU9bzLK",
        "outputId": "c5e4ec3b-9bc9-4ed8-de7d-5175850f1fec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- KNN Metrics ---\n",
            "Accuracy: 0.7063\n",
            "AUC: 0.7737\n",
            "Precision: 0.7202\n",
            "Recall: 0.7765\n",
            "F1 Score: 0.7473\n",
            "MCC: 0.3994\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Initialize and Train Model\n",
        "# n_neighbors=5 is a common default, but can be tuned\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred_knn = knn_model.predict(X_test_scaled)\n",
        "y_prob_knn = knn_model.predict_proba(X_test_scaled)[:, 1] # For AUC Score\n",
        "\n",
        "# Calculate Required Metrics [cite: 41, 42, 43, 44, 45, 46]\n",
        "knn_metrics = {\n",
        "    \"Accuracy\": accuracy_score(y_test, y_pred_knn),\n",
        "    \"AUC\": roc_auc_score(y_test, y_prob_knn),\n",
        "    \"Precision\": precision_score(y_test, y_pred_knn),\n",
        "    \"Recall\": recall_score(y_test, y_pred_knn),\n",
        "    \"F1 Score\": f1_score(y_test, y_pred_knn),\n",
        "    \"MCC\": matthews_corrcoef(y_test, y_pred_knn)\n",
        "}\n",
        "\n",
        "# Display Results\n",
        "print(\"--- KNN Metrics ---\")\n",
        "for metric, value in knn_metrics.items():\n",
        "    print(f\"{metric}: {value:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUMTehgAb8cf",
        "outputId": "8d39dd4c-381a-4e85-d8a3-856103499f82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Naive Bayes Metrics ---\n",
            "Accuracy: 0.7344\n",
            "AUC: 0.7927\n",
            "Precision: 0.7582\n",
            "Recall: 0.7709\n",
            "F1 Score: 0.7645\n",
            "MCC: 0.4600\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Initialize and Train Model\n",
        "nb_model = GaussianNB()\n",
        "nb_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred_nb = nb_model.predict(X_test_scaled)\n",
        "y_prob_nb = nb_model.predict_proba(X_test_scaled)[:, 1] # For AUC Score\n",
        "\n",
        "# Calculate Required Metrics [cite: 40-46]\n",
        "nb_metrics = {\n",
        "    \"Accuracy\": accuracy_score(y_test, y_pred_nb),\n",
        "    \"AUC\": roc_auc_score(y_test, y_prob_nb),\n",
        "    \"Precision\": precision_score(y_test, y_pred_nb),\n",
        "    \"Recall\": recall_score(y_test, y_pred_nb),\n",
        "    \"F1 Score\": f1_score(y_test, y_pred_nb),\n",
        "    \"MCC\": matthews_corrcoef(y_test, y_pred_nb)\n",
        "}\n",
        "\n",
        "# Display Results\n",
        "print(\"--- Naive Bayes Metrics ---\")\n",
        "for metric, value in nb_metrics.items():\n",
        "    print(f\"{metric}: {value:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pl__8tQHcE9_",
        "outputId": "a5a61d20-1190-4cea-caf9-0444bb277f7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Random Forest Metrics ---\n",
            "Accuracy: 0.7844\n",
            "AUC: 0.8919\n",
            "Precision: 0.8056\n",
            "Recall: 0.8101\n",
            "F1 Score: 0.8078\n",
            "MCC: 0.5623\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialize and Train Model\n",
        "# n_estimators=100 is the standard default for ensemble models\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred_rf = rf_model.predict(X_test_scaled)\n",
        "y_prob_rf = rf_model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# Calculate Required Metrics [cite: 40-46]\n",
        "rf_metrics = {\n",
        "    \"Accuracy\": accuracy_score(y_test, y_pred_rf),\n",
        "    \"AUC\": roc_auc_score(y_test, y_prob_rf),\n",
        "    \"Precision\": precision_score(y_test, y_pred_rf),\n",
        "    \"Recall\": recall_score(y_test, y_pred_rf),\n",
        "    \"F1 Score\": f1_score(y_test, y_pred_rf),\n",
        "    \"MCC\": matthews_corrcoef(y_test, y_pred_rf)\n",
        "}\n",
        "\n",
        "# Display Results\n",
        "print(\"--- Random Forest Metrics ---\")\n",
        "for metric, value in rf_metrics.items():\n",
        "    print(f\"{metric}: {value:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDQLd44fcPD8",
        "outputId": "18fb8ec5-a0eb-4161-c236-2e0fd18b00e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.1.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.29.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from xgboost) (1.16.3)\n",
            "--- XGBoost Metrics ---\n",
            "Accuracy: 0.8000\n",
            "AUC: 0.8796\n",
            "Precision: 0.8249\n",
            "Recall: 0.8156\n",
            "F1 Score: 0.8202\n",
            "MCC: 0.5949\n"
          ]
        }
      ],
      "source": [
        "!pip install xgboost\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Initialize and Train Model\n",
        "# n_estimators and learning_rate are common hyperparameters to tune\n",
        "xgb_model = XGBClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
        "xgb_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred_xgb = xgb_model.predict(X_test_scaled)\n",
        "y_prob_xgb = xgb_model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# Calculate Required Metrics\n",
        "xgb_metrics = {\n",
        "    \"Accuracy\": accuracy_score(y_test, y_pred_xgb),\n",
        "    \"AUC\": roc_auc_score(y_test, y_prob_xgb),\n",
        "    \"Precision\": precision_score(y_test, y_pred_xgb),\n",
        "    \"Recall\": recall_score(y_test, y_pred_xgb),\n",
        "    \"F1 Score\": f1_score(y_test, y_pred_xgb),\n",
        "    \"MCC\": matthews_corrcoef(y_test, y_pred_xgb)\n",
        "}\n",
        "\n",
        "# Display Results\n",
        "print(\"--- XGBoost Metrics ---\")\n",
        "for metric, value in xgb_metrics.items():\n",
        "    print(f\"{metric}: {value:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "eyxc2nyAcWgh"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import os\n",
        "\n",
        "# Create model directory if it doesn't exist\n",
        "os.makedirs('model', exist_ok=True)\n",
        "\n",
        "# Example: Saving the XGBoost model\n",
        "with open('model/xgb_model.pkl', 'wb') as f:\n",
        "    pickle.dump(xgb_model, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFSXHGLociWv",
        "outputId": "77c547da-8c92-4a46-d9f4-6b73a0e285d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.54.0-py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Collecting cachetools<7,>=5.5 (from streamlit)\n",
            "  Downloading cachetools-6.2.6-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.1)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.46)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (26.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.6)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (9.1.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (4.26.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2026.1.4)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.30.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.54.0-py3-none-any.whl (9.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cachetools-6.2.6-py3-none-any.whl (11 kB)\n",
            "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: cachetools, pydeck, streamlit\n",
            "  Attempting uninstall: cachetools\n",
            "    Found existing installation: cachetools 7.0.0\n",
            "    Uninstalling cachetools-7.0.0:\n",
            "      Successfully uninstalled cachetools-7.0.0\n",
            "Successfully installed cachetools-6.2.6 pydeck-0.9.1 streamlit-1.54.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2026-02-15 12:16:05.001 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2026-02-15 12:16:05.423 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.12/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2026-02-15 12:16:05.426 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2026-02-15 12:16:05.430 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2026-02-15 12:16:05.436 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2026-02-15 12:16:05.438 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2026-02-15 12:16:05.446 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2026-02-15 12:16:05.447 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2026-02-15 12:16:05.447 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2026-02-15 12:16:05.452 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2026-02-15 12:16:05.455 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2026-02-15 12:16:05.459 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2026-02-15 12:16:05.461 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2026-02-15 12:16:05.462 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2026-02-15 12:16:05.464 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2026-02-15 12:16:05.468 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2026-02-15 12:16:05.471 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2026-02-15 12:16:05.472 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2026-02-15 12:16:05.474 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2026-02-15 12:16:05.475 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2026-02-15 12:16:05.477 Session state does not function when running a script without `streamlit run`\n",
            "2026-02-15 12:16:05.482 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2026-02-15 12:16:05.484 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2026-02-15 12:16:05.489 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2026-02-15 12:16:05.491 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2026-02-15 12:16:05.493 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2026-02-15 12:16:05.496 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import os\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# App Title [cite: 9]\n",
        "st.title(\"ðŸ· Wine Quality Classification Dashboard\")\n",
        "\n",
        "# Step a: Dataset upload option (CSV) [cite: 91]\n",
        "st.sidebar.header(\"1. Upload Data\")\n",
        "uploaded_file = st.sidebar.file_uploader(\"Upload your test CSV file\", type=[\"csv\"])\n",
        "\n",
        "# Step b: Model selection dropdown [cite: 92]\n",
        "st.sidebar.header(\"2. Choose Model\")\n",
        "model_option = st.sidebar.selectbox(\n",
        "    \"Select a Classification Model\",\n",
        "    (\"Logistic Regression\", \"Decision Tree\", \"KNN\", \"Naive Bayes\", \"Random Forest\", \"XGBoost\")\n",
        ")\n",
        "\n",
        "def load_model(name):\n",
        "    # Mapping selection to saved filenames\n",
        "    model_map = {\n",
        "        \"Logistic Regression\": \"lr_model.pkl\",\n",
        "        \"Decision Tree\": \"dt_model.pkl\",\n",
        "        \"KNN\": \"knn_model.pkl\",\n",
        "        \"Naive Bayes\": \"nb_model.pkl\",\n",
        "        \"Random Forest\": \"rf_model.pkl\",\n",
        "        \"XGBoost\": \"xgb_model.pkl\"\n",
        "    }\n",
        "    with open(os.path.join('model', model_map[name]), 'rb') as f:\n",
        "        return pickle.load(f)\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    # Load test data [cite: 91]\n",
        "    test_df = pd.read_csv(uploaded_file)\n",
        "    st.write(\"### Test Data Preview\")\n",
        "    st.dataframe(test_df.head())\n",
        "\n",
        "    # Pre-processing (Assuming target column 'target' is present)\n",
        "    if 'target' in test_df.columns:\n",
        "        X_test = test_df.drop('target', axis=1)\n",
        "        y_test = test_df['target']\n",
        "\n",
        "        # Load selected model\n",
        "        model = load_model(model_option)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Step c: Display of evaluation metrics [cite: 93]\n",
        "        st.write(f\"## Evaluation Metrics: {model_option}\")\n",
        "        col1, col2, col3 = st.columns(3)\n",
        "\n",
        "        # Note: You can calculate these dynamically or display pre-saved values [cite: 40-45]\n",
        "        from sklearn.metrics import accuracy_score, f1_score\n",
        "        acc = accuracy_score(y_test, y_pred)\n",
        "        f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "        col1.metric(\"Accuracy\", f\"{acc:.2f}\")\n",
        "        col2.metric(\"F1 Score\", f\"{f1:.2f}\")\n",
        "\n",
        "        # Step d: Confusion matrix or classification report [cite: 94]\n",
        "        st.write(\"### Confusion Matrix\")\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "        fig, ax = plt.subplots()\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
        "        st.pyplot(fig)\n",
        "\n",
        "        st.write(\"### Classification Report\")\n",
        "        st.text(classification_report(y_test, y_pred))\n",
        "    else:\n",
        "        st.error(\"The uploaded CSV must contain a 'target' column for evaluation.\")\n",
        "else:\n",
        "    st.info(\"Please upload a test CSV file to begin.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4stLHl8FaN-",
        "outputId": "af106070-125c-449b-cd11-70b5fb6b4c51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded: (1599, 12)\n",
            "Features: ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol']\n",
            "Target distribution:\n",
            " target\n",
            "1    855\n",
            "0    744\n",
            "Name: count, dtype: int64\n",
            "Training all models...\n",
            "\n",
            "Training Logistic Regression...\n",
            "  Logistic Regression: Acc=0.7406, F1=0.7522\n",
            "Training Decision Tree...\n",
            "  Decision Tree: Acc=0.7531, F1=0.7710\n",
            "Training KNN...\n",
            "  KNN: Acc=0.7406, F1=0.7566\n",
            "Training Naive Bayes...\n",
            "  Naive Bayes: Acc=0.7219, F1=0.7227\n",
            "Training Random Forest...\n",
            "  Random Forest: Acc=0.8063, F1=0.8144\n",
            "Training XGBoost...\n",
            "  XGBoost: Acc=0.8250, F1=0.8333\n",
            "\n",
            "âœ… SUCCESS! Files saved:\n",
            "- models/*.pkl (6 models)\n",
            "- models/scaler.pkl\n",
            "- model_comparison.csv\n",
            "\n",
            "Comparison Table:\n",
            "   Accuracy     AUC  Precision  Recall      F1     MCC                Model\n",
            "0    0.7406  0.8242     0.7683  0.7368  0.7522  0.4808  Logistic Regression\n",
            "1    0.7531  0.7513     0.7644  0.7778  0.7710  0.5034        Decision Tree\n",
            "2    0.7406  0.8117     0.7588  0.7544  0.7566  0.4790                  KNN\n",
            "3    0.7219  0.7884     0.7733  0.6784  0.7227  0.4500          Naive Bayes\n",
            "4    0.8062  0.9018     0.8344  0.7953  0.8144  0.6128        Random Forest\n",
            "5    0.8250  0.8963     0.8485  0.8187  0.8333  0.6497              XGBoost\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
        "\n",
        "# Load DIRECT from UCI (no Kaggle needed, works everywhere)\n",
        "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
        "data = pd.read_csv(url, sep=';')\n",
        "print(\"Data loaded:\", data.shape)  # (1599, 12)\n",
        "\n",
        "# Create binary target (matches your notebook: >=6 = Good)\n",
        "data['target'] = (data['quality'] >= 6).astype(int)\n",
        "X = data.drop(['quality', 'target'], axis=1)\n",
        "y = data['target']\n",
        "\n",
        "print(\"Features:\", X.columns.tolist())\n",
        "print(\"Target distribution:\\n\", y.value_counts())\n",
        "\n",
        "# Split & scale\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# All models\n",
        "models_dict = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
        "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
        "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
        "    'Naive Bayes': GaussianNB(),\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    'XGBoost': XGBClassifier(n_estimators=100, random_state=42, eval_metric='logloss')\n",
        "}\n",
        "\n",
        "results = []\n",
        "os.makedirs('models', exist_ok=True)\n",
        "\n",
        "def compute_metrics(y_true, y_pred, y_proba):\n",
        "    return {\n",
        "        'Accuracy': accuracy_score(y_true, y_pred),\n",
        "        'AUC': roc_auc_score(y_true, y_proba[:, 1]),\n",
        "        'Precision': precision_score(y_true, y_pred),\n",
        "        'Recall': recall_score(y_true, y_pred),\n",
        "        'F1': f1_score(y_true, y_pred),\n",
        "        'MCC': matthews_corrcoef(y_true, y_pred)\n",
        "    }\n",
        "\n",
        "print(\"Training all models...\\n\")\n",
        "for name, model in models_dict.items():\n",
        "    print(f\"Training {name}...\")\n",
        "    if name in ['Decision Tree', 'Random Forest', 'XGBoost']:\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        y_proba = model.predict_proba(X_test)\n",
        "    else:\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "        y_pred = model.predict(X_test_scaled)\n",
        "        y_proba = model.predict_proba(X_test_scaled)\n",
        "\n",
        "    metrics = compute_metrics(y_test, y_pred, y_proba)\n",
        "    metrics['Model'] = name\n",
        "    results.append(metrics)\n",
        "    print(f\"  {name}: Acc={metrics['Accuracy']:.4f}, F1={metrics['F1']:.4f}\")\n",
        "\n",
        "    # Save with clean name\n",
        "    safe_name = name.lower().replace(' ', '_').replace('-', '')\n",
        "    joblib.dump(model, f'models/{safe_name}.pkl')\n",
        "\n",
        "# Final saves\n",
        "joblib.dump(scaler, 'models/scaler.pkl')\n",
        "comparison_df = pd.DataFrame(results).round(4)\n",
        "comparison_df.to_csv('model_comparison.csv', index=False)\n",
        "\n",
        "print(\"\\nâœ… SUCCESS! Files saved:\")\n",
        "print(\"- models/*.pkl (6 models)\")\n",
        "print(\"- models/scaler.pkl\")\n",
        "print(\"- model_comparison.csv\")\n",
        "print(\"\\nComparison Table:\")\n",
        "print(comparison_df)\n",
        "\n",
        "# BITS Lab proof: Download these files now!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l39-Bo8Fcxei",
        "outputId": "e3990c62-ac7b-4a9e-9321-d96eeed095d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files saved successfully!\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Create directory if it doesn't exist\n",
        "os.makedirs('models', exist_ok=True)\n",
        "\n",
        "# Save scaler\n",
        "joblib.dump(scaler, 'models/scaler.pkl')\n",
        "\n",
        "# Save all models using the correct variable names from your training cells\n",
        "joblib.dump(lr_model, 'models/lrmodel.pkl')\n",
        "joblib.dump(dt_model, 'models/dtmodel.pkl')\n",
        "joblib.dump(knn_model, 'models/knnmodel.pkl')\n",
        "joblib.dump(nb_model, 'models/nbmodel.pkl')\n",
        "joblib.dump(rf_model, 'models/rfmodel.pkl')\n",
        "joblib.dump(xgb_model, 'models/xgbmodel.pkl')\n",
        "\n",
        "# Save comparison CSV\n",
        "comparison_data = {\n",
        "    'Model': ['Logistic Regression', 'Decision Tree', 'KNN', 'Naive Bayes', 'Random Forest', 'XGBoost'],\n",
        "    'Accuracy': [0.7406, 0.7344, 0.7063, 0.7344, 0.7844, 0.8000],\n",
        "    'AUC': [0.8190, 0.7325, 0.7737, 0.7927, 0.8919, 0.8796],\n",
        "    'Precision': [0.7857, 0.7701, 0.7202, 0.7582, 0.8056, 0.8249],\n",
        "    'Recall': [0.7374, 0.7486, 0.7765, 0.7709, 0.8101, 0.8156],\n",
        "    'F1': [0.7608, 0.7592, 0.7473, 0.7645, 0.8078, 0.8202],\n",
        "    'MCC': [0.4793, 0.4634, 0.3994, 0.4600, 0.5623, 0.5949]\n",
        "}\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "comparison_df.to_csv('model_comparison.csv', index=False)\n",
        "\n",
        "print(\"Files saved successfully!\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}